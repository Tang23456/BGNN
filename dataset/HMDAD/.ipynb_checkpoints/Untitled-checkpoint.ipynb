{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a7b9b8-2334-49c3-a831-e6b8c69b6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 步骤1: 读取microbe.xlsx文件\n",
    "microbes_df = pd.read_excel('microbe.xlsx')\n",
    "\n",
    "# 步骤2: 读取species.tree.v12.0.txt文件，并创建映射\n",
    "species_df = pd.read_csv('species.v11.0.txt', sep='\\t')\n",
    "species_mapping_compact = dict(zip(species_df['STRING_name_compact'], species_df['## taxon_id']))\n",
    "species_mapping_official = dict(zip(species_df['official_name_NCBI'], species_df['## taxon_id']))\n",
    "\n",
    "# 步骤3: 查找每个微生物的TID\n",
    "tids = []\n",
    "for microbe in microbes_df['Microbe']:\n",
    "    tid = species_mapping_compact.get(microbe)\n",
    "    if tid is None:  # 如果在STRING_name_compact中找不到，则尝试在official_name_NCBI中查找\n",
    "        tid = species_mapping_official.get(microbe)\n",
    "    tids.append(tid)\n",
    "\n",
    "# 步骤4: 创建新的数据框\n",
    "microbes_df['TID'] = tids\n",
    "\n",
    "# 步骤5: 保存到新的Excel文件\n",
    "microbes_df.to_excel('micro_tid.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faff9b54-692b-4478-beb4-ffc79da86c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Microbe</th>\n",
       "      <th>Code</th>\n",
       "      <th>TID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Staphylococcus aureus</td>\n",
       "      <td>47</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bifidobacterium catenulatum</td>\n",
       "      <td>50</td>\n",
       "      <td>566552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Clostridium leptum</td>\n",
       "      <td>58</td>\n",
       "      <td>428125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bacteroides ovatus</td>\n",
       "      <td>81</td>\n",
       "      <td>411476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bacteroides uniformis</td>\n",
       "      <td>82</td>\n",
       "      <td>411479.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Microbe  Code       TID\n",
       "7         Staphylococcus aureus    47    1280.0\n",
       "10  Bifidobacterium catenulatum    50  566552.0\n",
       "18           Clostridium leptum    58  428125.0\n",
       "41           Bacteroides ovatus    81  411476.0\n",
       "42        Bacteroides uniformis    82  411479.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load microbe data\n",
    "microbes_df = pd.read_excel('./microbe.xlsx')\n",
    "\n",
    "# Load species data\n",
    "species_df = pd.read_csv('./species.v11.0.txt', sep='\\t')\n",
    "\n",
    "# Create dictionaries for lookup\n",
    "species_mapping_compact = dict(zip(species_df['STRING_name_compact'], species_df['## taxon_id']))\n",
    "species_mapping_official = dict(zip(species_df['official_name_NCBI'], species_df['## taxon_id']))\n",
    "\n",
    "# Initialize a list to hold the TIDs\n",
    "tids = []\n",
    "\n",
    "# Loop through each microbe to find its TID based on compact and official names\n",
    "for microbe in microbes_df['Microbe']:\n",
    "    tid = species_mapping_compact.get(microbe, species_mapping_official.get(microbe, None))\n",
    "    tids.append(tid)\n",
    "\n",
    "# Add the TIDs to the dataframe\n",
    "microbes_df['TID'] = tids\n",
    "\n",
    "# Filter out rows without a TID\n",
    "microbes_df_with_tid = microbes_df.dropna(subset=['TID'])\n",
    "\n",
    "# Save the filtered dataframe to a new Excel file\n",
    "microbes_df_with_tid.to_excel('./micro_tid_unique.xlsx', index=False)\n",
    "microbes_df_with_tid.to_csv('./micro_tid_unique.txt', index=False,sep='\\t')\n",
    "\n",
    "microbes_df_with_tid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88445ace-4efd-4389-ad0e-d81526181471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_taxonomy_id</th>\n",
       "      <th>orthgroup_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25866</th>\n",
       "      <td>573</td>\n",
       "      <td>COG0583</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25867</th>\n",
       "      <td>573</td>\n",
       "      <td>COG0477</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25868</th>\n",
       "      <td>573</td>\n",
       "      <td>COG2207</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25869</th>\n",
       "      <td>573</td>\n",
       "      <td>COG0454</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25870</th>\n",
       "      <td>573</td>\n",
       "      <td>COG1309</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       species_taxonomy_id orthgroup_id  count\n",
       "25866                  573      COG0583    111\n",
       "25867                  573      COG0477     78\n",
       "25868                  573      COG2207     37\n",
       "25869                  573      COG0454     32\n",
       "25870                  573      COG1309     31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载micro_tid_unique.txt文件\n",
    "microbe_df = pd.read_excel('micro_tid_unique.xlsx', engine='openpyxl')\n",
    "\n",
    "# 加载species.mappings.v11.0.txt文件\n",
    "species_mappings_df = pd.read_csv(\"species.mappings.v11.0.txt\", sep=\"\\t\", skiprows=1, names=[\"species_taxonomy_id\", \"orthgroup_id\", \"count\"])\n",
    "\n",
    "# 提取TID列并转换为整数（去除小数点）\n",
    "tids = microbe_df[\"TID\"].dropna().apply(int)\n",
    "\n",
    "# 保留species.mappings.v11.0.txt中TID对应的行\n",
    "filtered_species_mappings_df = species_mappings_df[species_mappings_df[\"species_taxonomy_id\"].isin(tids)]\n",
    "\n",
    "# 保存过滤后的DataFrame到文件\n",
    "filtered_species_mappings_df.to_csv(\"species.mapping.simple.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "filtered_species_mappings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2e4a17-863e-44c1-8289-b55f85097e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取两个Excel文件\n",
    "df_disease = pd.read_excel('disease.xlsx')\n",
    "df_mapping = pd.read_excel('./化学-疾病/disease_chemicals_mapping_unique_id.xlsx')\n",
    "\n",
    "# 剔除ChemicalNames和ChemicalIDs均为空的行\n",
    "df_mapping = df_mapping.dropna(subset=['ChemicalNames', 'ChemicalIDs'])\n",
    "\n",
    "# 创建字典将疾病名称映射到编码（将疾病名称转换为小写）\n",
    "disease_dict = dict(zip(df_disease['Disease'].str.lower(), df_disease['Code']))\n",
    "\n",
    "# 添加新的列，为疾病的编码\n",
    "df_mapping['Disease_Code'] = df_mapping['Disease'].str.lower().map(disease_dict)\n",
    "\n",
    "# 保存结果到新的Excel文件\n",
    "df_mapping.to_excel('./化学-疾病/mapped_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc7cab6-eb11-495f-9ebd-d3a7f601f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取两个Excel文件\n",
    "df_disease = pd.read_excel('disease.xlsx')\n",
    "df_mapping = pd.read_excel('./基因-疾病/disease_genes_mapping.xlsx')\n",
    "\n",
    "# 剔除ChemicalNames和ChemicalIDs均为空的行\n",
    "df_mapping = df_mapping.dropna(subset=['GeneSymbols', 'GeneIDs'])\n",
    "\n",
    "# 创建字典将疾病名称映射到编码（将疾病名称转换为小写）\n",
    "disease_dict = dict(zip(df_disease['Disease'].str.lower(), df_disease['Code']))\n",
    "\n",
    "# 添加新的列，为疾病的编码\n",
    "df_mapping['Disease_Code'] = df_mapping['Disease'].str.lower().map(disease_dict)\n",
    "\n",
    "# 保存结果到新的Excel文件\n",
    "df_mapping.to_excel('./基因-疾病/mapped_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65507f32-a8e3-41dc-bc52-b179ea592d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取两个Excel文件\n",
    "df_disease = pd.read_excel('disease.xlsx')\n",
    "df_mapping = pd.read_excel('./疾病-通路/disease_pathway_mapping_unique_id.xlsx')\n",
    "\n",
    "# 剔除ChemicalNames和ChemicalIDs均为空的行\n",
    "df_mapping = df_mapping.dropna(subset=['PathwayName', 'PathwayID'])\n",
    "\n",
    "# 创建字典将疾病名称映射到编码（将疾病名称转换为小写）\n",
    "disease_dict = dict(zip(df_disease['Disease'].str.lower(), df_disease['Code']))\n",
    "\n",
    "# 添加新的列，为疾病的编码\n",
    "df_mapping['Disease_Code'] = df_mapping['Disease'].str.lower().map(disease_dict)\n",
    "\n",
    "# 保存结果到新的Excel文件\n",
    "df_mapping.to_excel('./疾病-通路/mapped_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1652d03a-98b5-4d54-b00b-04d44d0f3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取disease.xlsx文件\n",
    "disease_df = pd.read_excel('disease.xlsx')\n",
    "\n",
    "# 读取data_with_id.txt文件\n",
    "with open('../data_with_id.txt', 'r', encoding='utf-8') as file:\n",
    "    data_with_id_lines = file.readlines()\n",
    "\n",
    "# 读取disease-symptom.txt文件\n",
    "with open('../疾病-症状相似性.txt', 'r', encoding='utf-8') as file:\n",
    "    disease_symptom_lines = file.readlines()\n",
    "\n",
    "# 解析data_with_id.txt，构建MeSH术语和同义词的映射\n",
    "mesh_dict = {}\n",
    "for line in data_with_id_lines:\n",
    "    parts = line.split('卍')\n",
    "    if len(parts) > 1:\n",
    "        term = parts[1].split('※')[0]\n",
    "        synonyms = parts[1].split('※')[1:]\n",
    "        for synonym in synonyms:\n",
    "            mesh_dict[synonym.strip()] = term.strip()\n",
    "\n",
    "# 解析disease-symptom.txt，构建疾病-症状映射\n",
    "disease_symptom_dict = {}\n",
    "for line in disease_symptom_lines:\n",
    "    parts = line.strip().split('\\t')\n",
    "    if len(parts) == 4:\n",
    "        symptom = parts[0]\n",
    "        disease = parts[1]\n",
    "        if disease not in disease_symptom_dict:\n",
    "            disease_symptom_dict[disease] = []\n",
    "        disease_symptom_dict[disease].append(symptom)\n",
    "\n",
    "# 查找disease.xlsx中的疾病对应的症状\n",
    "disease_symptoms = []\n",
    "for disease in disease_df['Disease']:\n",
    "    found_symptoms = []\n",
    "    # 尝试直接查找疾病名称\n",
    "    if disease in disease_symptom_dict:\n",
    "        found_symptoms = disease_symptom_dict[disease]\n",
    "    else:\n",
    "        # 尝试使用同义词查找\n",
    "        for synonym in mesh_dict:\n",
    "            if synonym == disease or disease in synonym:\n",
    "                mesh_term = mesh_dict[synonym]\n",
    "                if mesh_term in disease_symptom_dict:\n",
    "                    found_symptoms = disease_symptom_dict[mesh_term]\n",
    "                    break\n",
    "\n",
    "    # 将找到的症状记录下来，用逗号分隔\n",
    "    disease_symptoms.append(','.join(found_symptoms))\n",
    "\n",
    "# 将结果添加到disease.xlsx文件的症状列中\n",
    "disease_df['Symptoms'] = disease_symptoms\n",
    "\n",
    "# 保存结果到新的Excel文件\n",
    "disease_df.to_excel('./疾病-症状/disease_with_symptoms.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa56f5e0-36dc-4680-930d-2762708d57f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Disease  Code                   MeSH Codes\n",
      "0  Colon cancer     1  C04.588.274.476.411.307.190\n",
      "1  Colon cancer     1  C04.588.274.476.411.307.190\n",
      "2  Colon cancer     1                  C04.700.250\n",
      "3  Colon cancer     1                  C04.700.250\n",
      "4  Colon cancer     1      C06.301.371.411.307.190\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel('updated_diseases_with_id.xlsx')\n",
    "# 展开MeSH Codes列，其中每个MeSH代码都变为新行\n",
    "# stack()用于将数据在行之间堆叠，reset_index()用于重置索引，以便每个条目都有唯一的索引\n",
    "mesh_expanded = df.set_index(['Disease', 'Code'])['MeSH Codes'].str.split(',', expand=True).stack().reset_index(name='MeSH Codes')\n",
    "# 删除不必要的列（如果创建了额外的列）\n",
    "mesh_expanded.drop('level_2', axis=1, inplace=True)\n",
    "# 查看结果\n",
    "print(mesh_expanded.head())\n",
    "# 如果需要，将结果保存回Excel文件\n",
    "mesh_expanded.to_excel('updated_diseases_with_id_split.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca54c9c-c8a3-4016-a117-be4c9864d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Similarity Matrix:\n",
      " [[1.0e+00 5.3e-04 0.0e+00 ... 0.0e+00 0.0e+00 0.0e+00]\n",
      " [5.3e-04 1.0e+00 0.0e+00 ... 0.0e+00 0.0e+00 0.0e+00]\n",
      " [0.0e+00 0.0e+00 0.0e+00 ... 0.0e+00 0.0e+00 0.0e+00]\n",
      " ...\n",
      " [0.0e+00 0.0e+00 0.0e+00 ... 0.0e+00 0.0e+00 0.0e+00]\n",
      " [0.0e+00 0.0e+00 0.0e+00 ... 0.0e+00 0.0e+00 0.0e+00]\n",
      " [0.0e+00 0.0e+00 0.0e+00 ... 0.0e+00 0.0e+00 0.0e+00]]\n",
      "Model 2 Similarity Matrix:\n",
      " [[1.      0.01206 0.      ... 0.      0.      0.     ]\n",
      " [0.01206 1.      0.      ... 0.      0.      0.     ]\n",
      " [0.      0.      0.      ... 0.      0.      0.     ]\n",
      " ...\n",
      " [0.      0.      0.      ... 0.      0.      0.     ]\n",
      " [0.      0.      0.      ... 0.      0.      0.     ]\n",
      " [0.      0.      0.      ... 0.      0.      0.     ]]\n"
     ]
    }
   ],
   "source": [
    "################  疾病-语义   ###################\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "class GetSemanticSimilarity(object):  # 计算基于MeSH（医学主题词汇表）疾病信息的疾病语义相似性\n",
    "    \"\"\"\n",
    "    Get disease semantic similarity of MeSH\n",
    "    计算疾病的语义相似性，基于MeSH中的疾病信息。\n",
    "    初始化时，根据epsilon值计算两种模型的语义相似性。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id, disease, unique_disease, epsilon):\n",
    "        # 初始化时存储疾病的ID、名称和唯一名称列表，以及用于模型计算的epsilon值\n",
    "        # 类的初始化函数，接收四个参数：id（疾病ID列表）、disease（疾病名称列表）、unique_disease（疾病唯一名称列表）、epsilon（用于调整模型贡献度的参数）\n",
    "        # self.id, self.disease, self.unique_disease = id, disease, unique_disease\n",
    "        self.id = [str(i) for i in id if pd.notna(i)]\n",
    "        self.disease = [d for d, i in zip(disease, id) if pd.notna(i) and i != '']  # 过滤掉ids中为空的疾病名称\n",
    "        self.unique_disease = unique_disease  # 获取唯一疾病列表\n",
    "        self.epsilon = epsilon\n",
    "        self.semantic_sim1 = self.get_sim_model1(epsilon)  # 计算第一种模型的语义相似性\n",
    "        self.semantic_sim2 = self.get_sim_model2(epsilon)  # 计算第二种模型的语义相似性\n",
    "\n",
    "    def get_sim_model1(self, epsilon):\n",
    "        # 定义一个函数用于计算模型1的语义相似性\n",
    "        # Get id-disease pairs and unique diseases name in MeSH  # 使用Model 1计算每对疾病间的语义相似性，基于epsilon调整贡献度\n",
    "        # 深拷贝id, disease, unique_disease，以免在处理中修改原始数据\n",
    "        ids, diseases, unique_diseases = copy.deepcopy(self.id), copy.deepcopy(self.disease), copy.deepcopy(\n",
    "            self.unique_disease)\n",
    "\n",
    "        # Get contributions of model1  获取模型1的贡献度数据\n",
    "        unique_disease_dict = self.get_contributions(ids, diseases, unique_diseases, epsilon, flag=1)\n",
    "\n",
    "        # Compute similarity between every disease pair  计算所有疾病对之间的相似性\n",
    "        similarity = self.compute_similarity(unique_diseases, unique_disease_dict)\n",
    "\n",
    "        return similarity  # 返回相似性结果\n",
    "\n",
    "    def get_sim_model2(self, epsilon):  # 之前报错，改了后这里括号内引用了epsilon\n",
    "        # Get id-disease pairs and unique diseases name in MeSH   # 使用Model 2计算每对疾病间的语义相似性，基于初始加权贡献度 定义一个函数用于计算模型2的语义相似性\n",
    "        # 同样进行深拷贝以免修改原始数据\n",
    "        ids, diseases, unique_diseases = copy.deepcopy(self.id), copy.deepcopy(self.disease), copy.deepcopy(\n",
    "            self.unique_disease)\n",
    "\n",
    "        # Generate initial weighted contributions     计算加权贡献度，这里用对数函数调整每个ID的贡献度，并根据疾病总数进行归一化\n",
    "        dv_weighted = {}  # 存储每个ID的加权贡献度\n",
    "        all_ids = self.get_all_ids(ids)  # 获取所有疾病的ID\n",
    "        for key in all_ids:\n",
    "            dv_weighted[key] = round(math.log((dv_weighted.get(key, 0) + 1) / len(diseases), 10) * (-1), 5)\n",
    "\n",
    "        # Get final contributions of model2   获取模型2的贡献度数据，使用加权贡献度\n",
    "        ids, diseases, unique_diseases = copy.deepcopy(self.id), copy.deepcopy(self.disease), copy.deepcopy(\n",
    "            self.unique_disease)\n",
    "        unique_disease_dict = self.get_contributions(ids, diseases, unique_diseases, epsilon, flag=2,\n",
    "                                                     dv_weighted=dv_weighted)\n",
    "\n",
    "        # Compute similarity between every disease pair  计算所有疾病对之间的相似性\n",
    "        similarity = self.compute_similarity(unique_diseases, unique_disease_dict)\n",
    "\n",
    "        return similarity  # 返回相似性结果\n",
    "\n",
    "    def get_all_ids(self, ids):\n",
    "        \"\"\"Get all ids of diseases in MeSH\"\"\"  # 定义一个函数用于获取MeSH中所有疾病的ID\n",
    "        all_ids = []  # 存储所有ID\n",
    "        for i in range(len(ids)):\n",
    "            all_ids.append(ids[i])  # 添加原始ID\n",
    "            if len(ids[i]) > 3:  # 如果ID长度大于3，则继续提取\n",
    "                ids[i] = ids[i][:-4]  # 去掉最后四位来获取父级ID\n",
    "                all_ids.append(ids[i])  # 添加新提取的父级ID\n",
    "                # 循环截取ID的后四位，获取所有可能的父级ID\n",
    "                # 这个循环会不断执行，直到无法再削减ID（即ID长度不大于3），\n",
    "                # 这样可以从每个ID中提取出所有可能的父级ID变体\n",
    "\n",
    "                if len(ids[i]) > 3:\n",
    "                    ids[i] = ids[i][:-4]\n",
    "                    all_ids.append(ids[i])\n",
    "                    if len(ids[i]) > 3:\n",
    "                        ids[i] = ids[i][:-4]\n",
    "                        all_ids.append(ids[i])\n",
    "                        if len(ids[i]) > 3:\n",
    "                            ids[i] = ids[i][:-4]\n",
    "                            all_ids.append(ids[i])\n",
    "                            if len(ids[i]) > 3:\n",
    "                                ids[i] = ids[i][:-4]\n",
    "                                all_ids.append(ids[i])\n",
    "                                if len(ids[i]) > 3:\n",
    "                                    ids[i] = ids[i][:-4]\n",
    "                                    all_ids.append(ids[i])\n",
    "                                    if len(ids[i]) > 3:\n",
    "                                        ids[i] = ids[i][:-4]\n",
    "                                        all_ids.append(ids[i])\n",
    "                                        if len(ids[i]) > 3:\n",
    "                                            ids[i] = ids[i][:-4]\n",
    "                                            all_ids.append(ids[i])\n",
    "        return all_ids  # 返回包含所有ID及其变体的列表\n",
    "\n",
    "    def get_contributions(self, ids, diseases, unique_diseases, epsilon, flag, dv_weighted=None):\n",
    "\n",
    "        # 定义乘法操作来计算贡献度的衰减  定义一个函数用于计算疾病对之间的相似性   函数内部代码主要通过递归调整和累加贡献度\n",
    "        def multiply_operation(epsilon, num, k):\n",
    "            multiply_sum = 1\n",
    "            for i in range(num):  # 对于给定的深度，连续乘以epsilon\n",
    "                multiply_sum *= epsilon\n",
    "            return round(multiply_sum, k)  # 返回衰减后的值，保留k位小数\n",
    "\n",
    "        # Get initial contributions   # 初始化疾病字典，用于存储每个疾病的贡献度\n",
    "        disease_dict = {i: {} for i in range(len(diseases))}\n",
    "        for i in range(len(diseases)):  # 遍历每个疾病ID\n",
    "            if len(ids[i]) > 3:  # 如果疾病ID长度大于3，意味着可以进一步提取其父级ID\n",
    "                disease_dict[i][ids[i]] = 1 if flag == 1 else dv_weighted[ids[i]]  # 如果flag为1，则贡献度为1，否则使用预定义的权重\n",
    "                ids[i] = ids[i][:-4]  # 不断削减ID的最后四位，提取其父级ID，并根据提取的深度调整贡献度\n",
    "                if len(ids[i]) > 3:  # 对于每一级父级ID，使用epsilon计算衰减后的贡献度   # 此过程重复直到无法继续提取父级ID为止\n",
    "                    disease_dict[i][ids[i]] = multiply_operation(epsilon, 1, 5) if flag == 1 else dv_weighted[ids[i]]\n",
    "                    ids[i] = ids[i][:-4]\n",
    "                    if len(ids[i]) > 3:\n",
    "                        disease_dict[i][ids[i]] = multiply_operation(epsilon, 2, 5) if flag == 1 else dv_weighted[\n",
    "                            ids[i]]\n",
    "                        ids[i] = ids[i][:-4]\n",
    "                        if len(ids[i]) > 3:\n",
    "                            disease_dict[i][ids[i]] = multiply_operation(epsilon, 3, 5) if flag == 1 else dv_weighted[\n",
    "                                ids[i]]\n",
    "                            ids[i] = ids[i][:-4]\n",
    "                            if len(ids[i]) > 3:\n",
    "                                disease_dict[i][ids[i]] = multiply_operation(epsilon, 4, 5) if flag == 1 else \\\n",
    "                                dv_weighted[ids[i]]\n",
    "                                ids[i] = ids[i][:-4]\n",
    "                                if len(ids[i]) > 3:\n",
    "                                    disease_dict[i][ids[i]] = multiply_operation(epsilon, 5, 5) if flag == 1 else \\\n",
    "                                    dv_weighted[ids[i]]\n",
    "                                    ids[i] = ids[i][:-4]\n",
    "                                    if len(ids[i]) > 3:\n",
    "                                        disease_dict[i][ids[i]] = multiply_operation(epsilon, 6, 5) if flag == 1 else \\\n",
    "                                        dv_weighted[ids[i]]\n",
    "                                        ids[i] = ids[i][:-4]\n",
    "                                        if len(ids[i]) > 3:\n",
    "                                            disease_dict[i][ids[i]] = multiply_operation(epsilon, 7,\n",
    "                                                                                         5) if flag == 1 else \\\n",
    "                                            dv_weighted[ids[i]]\n",
    "                                            ids[i] = ids[i][:-4]\n",
    "                                        else:\n",
    "                                            disease_dict[i][ids[i][:3]] = multiply_operation(epsilon, 7,\n",
    "                                                                                             5) if flag == 1 else \\\n",
    "                                            dv_weighted[ids[i][:3]]\n",
    "                                    else:\n",
    "                                        disease_dict[i][ids[i][:3]] = multiply_operation(epsilon, 6,\n",
    "                                                                                         5) if flag == 1 else \\\n",
    "                                        dv_weighted[ids[i][:3]]\n",
    "                                else:\n",
    "                                    disease_dict[i][ids[i][:3]] = multiply_operation(epsilon, 5, 5) if flag == 1 else \\\n",
    "                                    dv_weighted[ids[i][:3]]\n",
    "                            else:\n",
    "                                disease_dict[i][ids[i][:3]] = multiply_operation(epsilon, 4, 5) if flag == 1 else \\\n",
    "                                dv_weighted[ids[i][:3]]\n",
    "                        else:\n",
    "                            disease_dict[i][ids[i][:3]] = multiply_operation(epsilon, 3, 5) if flag == 1 else \\\n",
    "                            dv_weighted[ids[i][:3]]\n",
    "                    else:\n",
    "                        disease_dict[i][ids[i][:3]] = multiply_operation(epsilon, 2, 5) if flag == 1 else dv_weighted[\n",
    "                            ids[i][:3]]\n",
    "                else:\n",
    "                    disease_dict[i][ids[i][:3]] = multiply_operation(epsilon, 1, 5) if flag == 1 else dv_weighted[\n",
    "                        ids[i][:3]]\n",
    "            else:\n",
    "                disease_dict[i][ids[i][:3]] = 1 if flag == 1 else dv_weighted[ids[i][:3]]\n",
    "\n",
    "        # Get final contribution after removing duplicate parts\n",
    "        unique_disease_dict = {}  # 初始化一个空字典，用于存储每个独特疾病的贡献度信息\n",
    "        for i in range(len(unique_diseases)):  # 遍历每个独特疾病\n",
    "            unique_disease_dict[i] = {}  # 为每个独特疾病创建一个空字典，用于存储其贡献度信息\n",
    "            for j in range(len(diseases)):  # 再次遍历所有疾病\n",
    "                if unique_diseases[i] == diseases[j]:  # 如果当前遍历到的独特疾病与任一疾病相同\n",
    "                    unique_disease_dict[i].update(disease_dict[j])  # 更新该独特疾病的贡献度信息\n",
    "                    # 使用.update方法将disease_dict[j]中的贡献度信息合并到unique_disease_dict[i]中\n",
    "                    # 这里的假设是，相同名字的疾病即使出现在不同的ID中，它们的贡献度信息是可以合并的\n",
    "\n",
    "        return unique_disease_dict  # 返回每个疾病的贡献度字典\n",
    "\n",
    "    def compute_similarity(self, unique_diseases, unique_disease_dict):\n",
    "        \"\"\"\n",
    "            计算疾病对之间的相似性。  定义一个函数用于计算疾病对之间的相似性\n",
    "        Calculate similarity every disease-disease pair\n",
    "        Args:\n",
    "            unique_diseases (list): unique disease names in MeSH\n",
    "            unique_disease_dict (dict): store the contribution of all disease-disease pairs\n",
    "        \"\"\"\n",
    "        similarity = np.zeros([len(unique_diseases), len(unique_diseases)])  # 初始化一个全零的二维数组，用于存储疾病对之间的相似性得分\n",
    "        # 计算相似性的逻辑代码\n",
    "        for m in range(len(unique_diseases)):  # 遍历每一个疾病m\n",
    "            for n in range(len(unique_diseases)):  # 再次遍历每一个疾病n\n",
    "                denominator = sum(unique_disease_dict[m].values()) + sum(\n",
    "                    unique_disease_dict[n].values())  # 计算分母，即两个疾病的贡献度之和\n",
    "                numerator = 0  # 初始化分子\n",
    "                if denominator == 0:\n",
    "                    similarity[m, n] = 0\n",
    "                else:\n",
    "                    for k, v in unique_disease_dict[m].items():  # 遍历疾病m的贡献度信息\n",
    "                        if k in unique_disease_dict[n].keys():  # 如果疾病n的贡献度信息中也有相同的键（即相同的疾病ID）\n",
    "\n",
    "                            numerator += (v + unique_disease_dict[n].get(k))  # 分子累加当前键对应的贡献度之和\n",
    "                    similarity[m, n] = round(numerator / denominator, 5)  # 计算相似性得分，并四舍五入到小数点后五位\n",
    "\n",
    "        return similarity  # 返回疾病对之间的相似性得分矩阵\n",
    "\n",
    "\n",
    "# %%\n",
    "df = pd.read_excel('updated_diseases_with_id_split.xlsx')  # 跳过第一行标题\n",
    "df2 = pd.read_excel('disease.xlsx')\n",
    "\n",
    "# 提取diseases和ids\n",
    "diseases = df.iloc[:, 0].tolist()  # 假设第一列为疾病名称\n",
    "ids = df.iloc[:, 2].tolist()  # 假设第三列为MeSH IDs\n",
    "# unique_diseases = list(set(diseases))  # 从疾病名称中提取唯一名称\n",
    "unique_diseases = df2.iloc[:, 0].tolist()\n",
    "# 设置epsilon值\n",
    "epsilon = 0.5\n",
    "\n",
    "# 创建类的实例\n",
    "similarity_calculator = GetSemanticSimilarity(ids, diseases, unique_diseases, epsilon)\n",
    "df_sim1 = pd.DataFrame(similarity_calculator.semantic_sim1)\n",
    "df_sim2 = pd.DataFrame(similarity_calculator.semantic_sim2)\n",
    "# 打印结果，仅作为示例\n",
    "print(\"Model 1 Similarity Matrix:\\n\", similarity_calculator.semantic_sim1)\n",
    "print(\"Model 2 Similarity Matrix:\\n\", similarity_calculator.semantic_sim2)\n",
    "df_sim1.to_csv(\"./疾病-语义/similarity_matrix_model1.csv\", index=False, header=False)\n",
    "df_sim2.to_csv(\"./疾病-语义/similarity_matrix_model2.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b575ea-b1a2-4d5f-a475-7cbf5c70c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class GetFunctionalSimilarity(object):\n",
    "    \"\"\"\n",
    "        根据微生物与疾病的关联矩阵以及疾病的语义相似性，计算微生物的功能相似性矩阵。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, circ_dis_matrix, n_circ, dis_semantic_sim):\n",
    "        # 类的初始化方法，接收circRNA与疾病的关联矩阵、circRNA数量以及疾病的语义相似性矩阵作为参数。\n",
    "        self.circ_sim_matrix = self.get_sim_matrix(n_circ, circ_dis_matrix, dis_semantic_sim)\n",
    "        # 计算并存储circRNA的功能相似性矩阵。\n",
    "\n",
    "    def get_sim_matrix(self, n_circ, circ_dis_matrix, dis_semantic_sim):  # 计算circRNA的功能相似性矩阵，其形状为(n_circ, n_circ)。\n",
    "        \"\"\"Get functional similarity matrix of circRNAs and its shape is (n_circ, n_circ)\"\"\"\n",
    "        sim_matrix = np.zeros((n_circ, n_circ), dtype=np.float32)  # 初始化一个全零的二维数组，用于存储circRNA之间的功能相似性得分\n",
    "        for i in range(n_circ):  # 遍历每个circRNA。\n",
    "            idx = np.nonzero(circ_dis_matrix[i, :])[0]  # 获取当前circRNA相关联的疾病的索引。\n",
    "            #idx = np.nonzero(circ_dis_matrix.iloc[i, :])[0]\n",
    "            if idx.size == 0:\n",
    "                continue  # 如果当前circRNA没有相关联的疾病，则跳过。\n",
    "\n",
    "            for j in range(i):  # 遍历当前circRNA之前的所有circRNA，避免重复计算。\n",
    "                idy = np.nonzero(circ_dis_matrix[j, :])[0]  # 获取另一个circRNA相关联的疾病的索引。\n",
    "                if idy.size == 0:\n",
    "                    continue  # 如果另一个circRNA没有相关联的疾病，则跳过。\n",
    "                sum1, sum2 = 0, 0  # 初始化两个变量用于累加计算。\n",
    "                for k1 in range(len(idx)):  # 遍历当前circRNA相关联的所有疾病。\n",
    "                    sum1 = sum1 + max(dis_semantic_sim[idx[k1], idy])  # 计算当前circRNA与另一个circRNA的疾病之间的最大语义相似性，并累加。\n",
    "                for k2 in range(len(idy)):  # 遍历另一个circRNA相关联的所有疾病。\n",
    "                    sum2 = sum2 + max(dis_semantic_sim[idx, idy[k2]])  # 同样计算并累加。\n",
    "                sim_matrix[i, j] = (sum1 + sum2) / (len(idx) + len(idy))  # 计算两个circRNA之间的功能相似性得分，并赋值给相应位置。\n",
    "                sim_matrix[j, i] = sim_matrix[i, j]  # 由于相似性矩阵是对称的，所以对应位置也赋相同的值。\n",
    "\n",
    "            for k in range(n_circ):  # 将对角线上的值设为1，表示每个circRNA与自身的相似性为最大值。\n",
    "                sim_matrix[k, k] = 1\n",
    "\n",
    "        return sim_matrix  # 返回计算好的功能相似性矩阵。\n",
    "\n",
    "# 读取微生物名称\n",
    "micro_df = pd.read_excel('microbe.xlsx')\n",
    "n_circ = len(micro_df)  # 获取微生物数量\n",
    "\n",
    "# 读取关联矩阵\n",
    "#circ_dis_matrix = pd.read_excel('adjacency_matrix.csv').values\n",
    "circ_dis_matrix = pd.read_excel('adj_mat.xlsx').values\n",
    "circ_dis_matrix = circ_dis_matrix[1:,1:]\n",
    "# 读取疾病语义相似性矩阵\n",
    "dis_semantic_sim = pd.read_csv('./疾病-语义/similarity_matrix_model1.csv',header = None).values\n",
    "\n",
    "similarity_calculator = GetFunctionalSimilarity(circ_dis_matrix.T, n_circ, dis_semantic_sim)\n",
    "functional_similarity_matrix = similarity_calculator.circ_sim_matrix\n",
    "# 将结果保存到CSV文件中\n",
    "pd.DataFrame(functional_similarity_matrix).to_csv('./基于疾病语义的微生物功能/functional_similarity1_matrix.csv', index=False)\n",
    "\n",
    "dis_semantic_sim = pd.read_csv('./疾病-语义/similarity_matrix_model2.csv',header = None).values\n",
    "\n",
    "similarity_calculator = GetFunctionalSimilarity(circ_dis_matrix.T, n_circ, dis_semantic_sim)\n",
    "functional_similarity_matrix = similarity_calculator.circ_sim_matrix\n",
    "# 将结果保存到CSV文件中\n",
    "pd.DataFrame(functional_similarity_matrix).to_csv('./基于疾病语义的微生物功能/functional_similarity2_matrix.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886952ba-5b60-49ff-a494-9e18b2003a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 292)\n",
      "292\n",
      "     0         1         2         3         4         5    6         7    \\\n",
      "0    1.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "1    0.0  1.000000  0.500000  0.666667  0.500000  0.000000  0.0  0.500000   \n",
      "2    0.0  0.500000  1.000000  0.333333  1.000000  0.000000  0.0  0.000000   \n",
      "3    0.0  0.666667  0.333333  1.000000  0.333333  0.149071  0.0  0.333333   \n",
      "4    0.0  0.500000  1.000000  0.333333  1.000000  0.000000  0.0  0.000000   \n",
      "..   ...       ...       ...       ...       ...       ...  ...       ...   \n",
      "287  0.0  0.500000  0.000000  0.333333  0.000000  0.000000  0.0  0.000000   \n",
      "288  0.0  0.500000  0.000000  0.333333  0.000000  0.000000  0.0  0.000000   \n",
      "289  0.0  0.500000  0.000000  0.333333  0.000000  0.000000  0.0  0.000000   \n",
      "290  0.0  0.500000  0.000000  0.333333  0.000000  0.000000  0.0  0.000000   \n",
      "291  0.0  0.500000  0.000000  0.333333  0.000000  0.000000  0.0  0.000000   \n",
      "\n",
      "          8         9    ...       282       283       284       285  \\\n",
      "0    0.000000  0.707107  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "1    0.288675  0.000000  ...  0.500000  0.500000  0.500000  0.500000   \n",
      "2    0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "3    0.384900  0.000000  ...  0.333333  0.333333  0.333333  0.333333   \n",
      "4    0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "..        ...       ...  ...       ...       ...       ...       ...   \n",
      "287  0.000000  0.000000  ...  1.000000  1.000000  1.000000  1.000000   \n",
      "288  0.000000  0.000000  ...  1.000000  1.000000  1.000000  1.000000   \n",
      "289  0.000000  0.000000  ...  1.000000  1.000000  1.000000  1.000000   \n",
      "290  0.000000  0.000000  ...  1.000000  1.000000  1.000000  1.000000   \n",
      "291  0.000000  0.000000  ...  1.000000  1.000000  1.000000  1.000000   \n",
      "\n",
      "          286       287       288       289       290       291  \n",
      "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1    0.500000  0.500000  0.500000  0.500000  0.500000  0.500000  \n",
      "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3    0.333333  0.333333  0.333333  0.333333  0.333333  0.333333  \n",
      "4    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "..        ...       ...       ...       ...       ...       ...  \n",
      "287  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
      "288  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
      "289  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
      "290  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
      "291  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
      "\n",
      "[292 rows x 292 columns]\n",
      "(292, 292)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "##drug 627 microbe 142\n",
    "#基于余弦的功能相似性\n",
    "association = pd.read_excel(\"./adj_mat.xlsx\", header=None).to_numpy()\n",
    "association = association[1:,:]\n",
    "association = association[1:,1:]\n",
    "def Cosine_Sim_row(M):\n",
    "    l=len(M)\n",
    "    print(l)\n",
    "    SM = np.zeros((l, l))\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            v1=np.dot(M[i],M[j])\n",
    "            v2=np.linalg.norm(M[i],ord=2)                       #计算L2范数\n",
    "            v3=np.linalg.norm(M[j],ord=2)\n",
    "            if v2*v3==0:\n",
    "                SM[i][j]=0\n",
    "            else:\n",
    "                SM[i][j]=v1/(v2*v3)\n",
    "    return SM\n",
    "print(association.shape)\n",
    "Cos_Matrix= pd.DataFrame(Cosine_Sim_row(association.T))\n",
    "Cos_Matrix.to_csv('./基于关联矩阵的微生物功能/Cosine_Sim.csv')\n",
    "print(Cos_Matrix)\n",
    "print(Cos_Matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f824f246-3b72-4891-b7bd-5be9e23840ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 292)\n",
      "39\n",
      "[[1.         0.38545403 0.84085728 ... 0.35345468 0.77105159 0.84085728]\n",
      " [0.38545403 1.         0.38545403 ... 0.16202575 0.35345468 0.38545403]\n",
      " [0.84085728 0.38545403 1.         ... 0.35345468 0.77105159 0.84085728]\n",
      " ...\n",
      " [0.35345468 0.16202575 0.35345468 ... 1.         0.32411183 0.35345468]\n",
      " [0.77105159 0.35345468 0.77105159 ... 0.32411183 1.         0.77105159]\n",
      " [0.84085728 0.38545403 0.84085728 ... 0.35345468 0.77105159 1.        ]]\n",
      "(39, 39)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "A = pd.read_excel(\"./adj_mat.xlsx\", header=None).to_numpy()\n",
    "A_array = A[1:,:]\n",
    "A_array = A_array[1:,1:]\n",
    "print(A_array.shape)\n",
    "# print(A_array)\n",
    "def GIP_Calculate(M):    #计算微生物高斯核相似性\n",
    "    l=np.size(M,axis=1)#这行代码中，np.size(M,axis=1)的作用是获取输入数组M的列数。\n",
    "    print(l)\n",
    "    # 其中np.size()是numpy库中的函数，用于计算数组的元素总数，也可以指定参数axis表示计算某一维度上的元素个数。\n",
    "    # 在本行代码中，指定axis=1表示要计算输入数组的列数。因此，l就是输入数组M的列数，也就是表示微生物数量的值。\n",
    "    sm=[]\n",
    "    m=np.zeros((l,l))\n",
    "    for i in range(l):                           # 对于M的每一列（代表一个微生物），计算其L2范数的平方，并将结果添加到列表sm中。\n",
    "        tmp=(np.linalg.norm(M[:,i]))**2\n",
    "        sm.append(tmp)\n",
    "    gama=l/np.sum(sm)\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            m[i,j]=np.exp(-gama*((np.linalg.norm(M[:,i]-M[:,j]))**2))\n",
    "    return m\n",
    "\n",
    "Smg=GIP_Calculate(A_array.T)\n",
    "print(Smg)\n",
    "print(Smg.shape)\n",
    "result = pd.DataFrame(Smg)\n",
    "result.to_csv('./基于关联矩阵的疾病相似性/GIP_Sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14799012-b81c-4783-af2a-e8d442ef0981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 292)\n",
      "39\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0   1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1   0.000000  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  1.000000  1.000000  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  1.000000  1.000000  0.000000  0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000   \n",
      "5   0.000000  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000   \n",
      "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000   \n",
      "7   0.154303  0.048795  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "9   0.000000  0.000000  0.000000  0.000000  0.353553  0.000000  0.000000   \n",
      "10  0.000000  0.111803  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "11  0.000000  0.062017  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "16  0.000000  0.000000  0.000000  0.000000  0.447214  0.000000  0.000000   \n",
      "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "20  0.000000  0.000000  1.000000  1.000000  0.000000  0.000000  0.000000   \n",
      "21  0.000000  0.210819  0.333333  0.333333  0.000000  0.000000  0.000000   \n",
      "22  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "23  0.000000  0.000000  0.000000  0.000000  0.333333  0.000000  0.000000   \n",
      "24  0.000000  0.182574  0.000000  0.000000  0.000000  0.000000  0.408248   \n",
      "25  0.000000  0.119523  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "26  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "27  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "28  0.000000  0.239046  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "29  0.000000  0.000000  0.000000  0.000000  0.000000  0.316228  0.000000   \n",
      "30  0.000000  0.122352  0.000000  0.000000  0.000000  0.077382  0.054718   \n",
      "31  0.000000  0.239046  0.000000  0.000000  0.000000  0.377964  0.000000   \n",
      "32  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "33  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "34  0.000000  0.200805  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "35  0.000000  0.000000  1.000000  1.000000  0.000000  0.000000  0.000000   \n",
      "36  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "37  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "38  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "          7         8         9   ...        29        30        31   32   33  \\\n",
      "0   0.154303  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "1   0.048795  0.000000  0.000000  ...  0.000000  0.122352  0.239046  0.0  0.0   \n",
      "2   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "4   0.000000  0.000000  0.353553  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "5   0.000000  0.000000  0.000000  ...  0.316228  0.077382  0.377964  0.0  0.0   \n",
      "6   0.000000  0.000000  0.000000  ...  0.000000  0.054718  0.000000  0.0  0.0   \n",
      "7   1.000000  0.154303  0.109109  ...  0.146385  0.131344  0.116642  0.0  0.0   \n",
      "8   0.154303  1.000000  0.000000  ...  0.000000  0.077382  0.000000  0.0  0.0   \n",
      "9   0.109109  0.000000  1.000000  ...  0.223607  0.054718  0.267261  0.0  0.0   \n",
      "10  0.163663  0.000000  0.000000  ...  0.111803  0.164153  0.133631  0.0  0.0   \n",
      "11  0.000000  0.000000  0.069338  ...  0.248069  0.091056  0.148250  0.0  0.0   \n",
      "12  0.154303  0.000000  0.000000  ...  0.000000  0.077382  0.377964  0.0  0.0   \n",
      "13  0.178174  0.000000  0.000000  ...  0.365148  0.089353  0.000000  0.0  0.0   \n",
      "14  0.082479  0.000000  0.094491  ...  0.169031  0.082725  0.101015  0.0  0.0   \n",
      "15  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "16  0.000000  0.000000  0.158114  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "17  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "18  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "19  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "20  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "21  0.154303  0.000000  0.117851  ...  0.210819  0.103176  0.251976  0.0  0.0   \n",
      "22  0.178174  0.000000  0.000000  ...  0.182574  0.134030  0.000000  0.0  0.0   \n",
      "23  0.051434  0.000000  0.117851  ...  0.105409  0.025794  0.000000  0.0  0.0   \n",
      "24  0.089087  0.000000  0.000000  ...  0.182574  0.089353  0.218218  0.0  0.0   \n",
      "25  0.058321  0.000000  0.133631  ...  0.239046  0.116991  0.142857  0.0  0.0   \n",
      "26  0.199205  0.258199  0.182574  ...  0.244949  0.139860  0.195180  0.0  0.0   \n",
      "27  0.089087  0.000000  0.000000  ...  0.000000  0.044677  0.000000  0.0  0.0   \n",
      "28  0.174964  0.000000  0.133631  ...  0.358569  0.146239  0.285714  0.0  0.0   \n",
      "29  0.146385  0.000000  0.223607  ...  1.000000  0.122352  0.358569  0.0  0.0   \n",
      "30  0.131344  0.077382  0.054718  ...  0.122352  1.000000  0.175487  0.0  0.0   \n",
      "31  0.116642  0.000000  0.267261  ...  0.358569  0.175487  1.000000  0.0  0.0   \n",
      "32  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  1.0  0.0   \n",
      "33  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  1.0   \n",
      "34  0.293948  0.127000  0.044901  ...  0.240966  0.226034  0.192006  0.0  0.0   \n",
      "35  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "36  0.232621  0.000000  0.213201  ...  0.286039  0.233316  0.227921  0.0  0.0   \n",
      "37  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "38  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.0  0.0   \n",
      "\n",
      "          34        35        36   37   38  \n",
      "0   0.000000  0.000000  0.000000  0.0  0.0  \n",
      "1   0.200805  0.000000  0.000000  0.0  0.0  \n",
      "2   0.000000  1.000000  0.000000  0.0  0.0  \n",
      "3   0.000000  1.000000  0.000000  0.0  0.0  \n",
      "4   0.000000  0.000000  0.000000  0.0  0.0  \n",
      "5   0.000000  0.000000  0.000000  0.0  0.0  \n",
      "6   0.000000  0.000000  0.000000  0.0  0.0  \n",
      "7   0.293948  0.000000  0.232621  0.0  0.0  \n",
      "8   0.127000  0.000000  0.000000  0.0  0.0  \n",
      "9   0.044901  0.000000  0.213201  0.0  0.0  \n",
      "10  0.134704  0.000000  0.106600  0.0  0.0  \n",
      "11  0.124534  0.000000  0.059131  0.0  0.0  \n",
      "12  0.127000  0.000000  0.000000  0.0  0.0  \n",
      "13  0.073324  0.000000  0.174078  0.0  0.0  \n",
      "14  0.169711  0.000000  0.080582  0.0  0.0  \n",
      "15  0.000000  0.000000  0.000000  0.0  0.0  \n",
      "16  0.000000  0.000000  0.000000  0.0  0.0  \n",
      "17  0.000000  0.000000  0.000000  0.0  0.0  \n",
      "18  0.000000  0.000000  0.000000  0.0  0.0  \n",
      "19  0.000000  0.000000  0.000000  0.0  0.0  \n",
      "20  0.000000  1.000000  0.000000  0.0  0.0  \n",
      "21  0.169334  0.333333  0.201008  0.0  0.0  \n",
      "22  0.146647  0.000000  0.348155  0.0  0.0  \n",
      "23  0.042333  0.000000  0.000000  0.0  0.0  \n",
      "24  0.073324  0.000000  0.000000  0.0  0.0  \n",
      "25  0.096003  0.000000  0.227921  0.0  0.0  \n",
      "26  0.131165  0.000000  0.233550  0.0  0.0  \n",
      "27  0.073324  0.000000  0.000000  0.0  0.0  \n",
      "28  0.240008  0.000000  0.227921  0.0  0.0  \n",
      "29  0.240966  0.000000  0.286039  0.0  0.0  \n",
      "30  0.226034  0.000000  0.233316  0.0  0.0  \n",
      "31  0.192006  0.000000  0.227921  0.0  0.0  \n",
      "32  0.000000  0.000000  0.000000  0.0  0.0  \n",
      "33  0.000000  0.000000  0.000000  0.0  0.0  \n",
      "34  1.000000  0.000000  0.229752  0.0  0.0  \n",
      "35  0.000000  1.000000  0.000000  0.0  0.0  \n",
      "36  0.229752  0.000000  1.000000  0.0  0.0  \n",
      "37  0.000000  0.000000  0.000000  1.0  0.0  \n",
      "38  0.000000  0.000000  0.000000  0.0  1.0  \n",
      "\n",
      "[39 rows x 39 columns]\n",
      "(39, 39)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "##drug 627 microbe 142\n",
    "#基于余弦的功能相似性\n",
    "association = pd.read_excel(\"./adj_mat.xlsx\", header=None).to_numpy()\n",
    "association = association[1:,:]\n",
    "association = association[1:,1:]\n",
    "def Cosine_Sim_row(M):\n",
    "    l=len(M)\n",
    "    print(l)\n",
    "    SM = np.zeros((l, l))\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            v1=np.dot(M[i],M[j])\n",
    "            v2=np.linalg.norm(M[i],ord=2)                       #计算L2范数\n",
    "            v3=np.linalg.norm(M[j],ord=2)\n",
    "            if v2*v3==0:\n",
    "                SM[i][j]=0\n",
    "            else:\n",
    "                SM[i][j]=v1/(v2*v3)\n",
    "    return SM\n",
    "print(association.shape)\n",
    "Cos_Matrix= pd.DataFrame(Cosine_Sim_row(association))\n",
    "Cos_Matrix.to_csv('./基于关联矩阵的疾病相似性/Cosine_Sim.csv')\n",
    "print(Cos_Matrix)\n",
    "print(Cos_Matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348a852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
